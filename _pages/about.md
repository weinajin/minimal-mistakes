---
permalink: /
author_profile: true
redirect_from:
  - /about/
  - /about.html
---



## About Weina

Hi, I'm Weina. I'm a PhD student working on **interpretable AI (artificial intelligence)**, and how to use it to augment doctors' **clinical decision making** based on **medical image** tasks.
<!-- It is interdisciplinary research among AI, computer vision, information visualization (InfoVis), human-computer interaction (HCI), and medicine. An explanation is a two-way communication/interaction between AI system and its users, that's where HCI and InfoVis come in. -->
I'm especially interested in using explanations for better learning, for both AI (enable AI to learn better by forcing explicit representation) and doctors (learn from those explicit representations to accumulate experience from big clinical data).

Previous I received my **Doctor of Medicine (MD)** degree and had worked in the hospital, pharmaceutical and tech company. Now besides my research in training and making sense of artificial intelligence, in my life I am engaged in training and understanding natural intelligence, and writing science fictions.


## News 

* 2021-07 Our paper <a href="http://weina.me/one-map-not-fit-all" target="_blank">One Map Does Not Fit All: Evaluating Saliency Map Explanation on Multi-Modal Medical Images</a> is accepted as the <a href="https://sites.google.com/view/imlh2021/" target="_blank">Spotlight paper of ICML 2021 Workshop: Interpretable Machine Learning in Healthcare.</a>

* 2021-01-01 I launched the End-User-Centered Explainable AI framework EUCA website: [https://weina.me/end-user-xai](https://weina.me/end-user-xai). EUCA is a practical prototyping tool to design explainable AI for non-technical end-users.


## Preprints and Work-In-Progress


### **One Map Does Not Fit All: Evaluating Saliency Map Explanation on Multi-Modal Medical Images**. 

**Weina Jin**, Xiaoxiao Li, Ghassan Hamarneh (2021). 
[arXiv:2107.05047](https://arxiv.org/abs/2107.05047). [Video](https://youtu.be/J-ceZ20cBJk). [Project Website](http://weina.me/one-map-not-fit-all).
<a href="https://sites.google.com/view/imlh2021/" target="_blank">Spotlight paper of ICML 2021 Workshop: Interpretable Machine Learning in Healthcare.</a>

<img src="/images/poster_ thumbnail_One Map Does Not Fit All_Evaluating Saliency Map Explanation on Multi-Modal Medical Images.png" alt="Evaluating Multi-Modal Medical Image Explanation" style="float: right;" height="200"/>
  - Propose the problem of multi-modal medical image explanation.
  - Propose the evaluation metric MSFI and conducted experiments to evaluate saliency maps regarding their abilities to fulfill clinical requirements for multi-modal medical image explanation.

### **EUCA: the End-User-Centered Explainable AI Prototyping Framework**. 

**Weina Jin**, Jianyu Fan, Diane Gromala, Philippe Pasquier, Ghassan Hamarneh (2020). (In Submission to TOCHI). 
[arXiv:2102.02437](https://arxiv.org/abs/2102.02437). [Project Website](http://https://weina.me/end-user-xai)

<img src="/images/EUCA.png" alt="End-User-Centered Explainable AI Prototyping Framework" style="float: right;" height="200"/>
  - Help explainable AI designers and practitioners to understand end-users' requirements for explainable AI.
  - Provide prototyping workflow/examples/templates to enable explainable AI designers and researchers to quickly design/iterate XAI prototypes.

## Publications


**Artificial intelligence in glioma imaging: challenges and advances**. 

**Jin, W.**, Fatehi, M., Abhishek, K., Mallya, M., Toyota, B., & Hamarneh, G. (2020). *Journal of Neural Engineering*. [doi: 10.1088/1741-2552/ab8131](https://iopscience.iop.org/article/10.1088/1741-2552/ab8131). [arXiv:1911.12886](https://arxiv.org/abs/1911.12886). [Paper](https://arxiv.org/pdf/1911.12886.pdf), [Video Abstract](https://www.youtube.com/watch?v=i2rX6NSH27k)

<img src="/images/brain_review_paper_outline.jpg" alt="brain_review_paper_outline" style="float: right;" width="400"/>
  - It summarizes the recent technical advances that aim to make AI implementable in neuro-oncology.
  - These challenges involve the full life-cycle of developing an AI model, from obtaining the training data, to training the AI models, to evaluating and deploying the AI model in clinical settings.


**Bridging AI Developers and End Users: an End-User-Centred Explainable AI Taxonomy and Visual Vocabularies**. 

**Jin, W.**, Carpendale, S., Hamarneh, G., & Gromala, D. (2019). *IEEE VIS 2019 Conference Poster Abstract*. [***Best Poster Design Award***]
[Paper](/files/Bridging AI Developers and End Users--an End-User-Centred Explainable AI Taxonomy and Visual Vocabularies.pdf), [Poster](/files/201910_IEEE_VIS_poster.pdf), [Video Abstract](https://www.youtube.com/watch?v=b5JnaSG1AYM)
<img src="/images/end_user_xai_image.jpg" alt="end_user_xai_image" style="float: right;" width="400"/>
  - It summarizes three user-friendly forms to explain AI's decision to end users: explaining using *features*, *examples*, and *rules*.
